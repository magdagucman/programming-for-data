{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdT0fwTCa4gI"
   },
   "source": [
    "# Working with Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozWLM6Pfa7d_"
   },
   "source": [
    "### Exercise 1 strings\n",
    "---\n",
    "The pandas library has a similar set of string functions to those available in python generally.  Because we often want to perform operations on a whole series of data values in a dataframe, we can use pandas string functions to do this:\n",
    "\n",
    "Let's use the data set 'Housing in London' at 'https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\n",
    "\n",
    "Read the dataset into a pandas dataframe and inspect the data.  The date, in this dataset is a string.   If we want to filter for a particular year, we will need to extract the first four letters as a substring.  We can create a new column called **year**, which just contains the year, stored as a number.\n",
    "\n",
    "The date is written in the format yyyy-mm-dd.  We can split the year around the '-' and then use the first component, converting it to an integer\n",
    "\n",
    "Reference:  \n",
    "\n",
    "Series.str.split() *to split a column's strings into components*    \n",
    "Series.str.get() *to get one of the components after the split*  \n",
    "\n",
    "You can **daisychain** these together:   \n",
    "\n",
    "`Series.str.split().str.get()`\n",
    "\n",
    "Have a go\n",
    "\n",
    "**Test output**:  \n",
    "\n",
    "```\n",
    "0       1999\n",
    "1       1999\n",
    "2       1999\n",
    "3       1999\n",
    "4       1999\n",
    "        ... \n",
    "1066    2019\n",
    "1067    2019\n",
    "1068    2019\n",
    "1069    2019\n",
    "1070    2019\n",
    "Name: year, Length: 1071, dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZuLewd421t_c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of            code                  area        date  median_salary  \\\n",
       "0     E09000001        city of london  1999-12-01        33020.0   \n",
       "1     E09000002  barking and dagenham  1999-12-01        21480.0   \n",
       "2     E09000003                barnet  1999-12-01        19568.0   \n",
       "3     E09000004                bexley  1999-12-01        18621.0   \n",
       "4     E09000005                 brent  1999-12-01        18532.0   \n",
       "...         ...                   ...         ...            ...   \n",
       "1066  K03000001         great britain  2019-12-01        30446.0   \n",
       "1067  K04000001     england and wales  2019-12-01        30500.0   \n",
       "1068  N92000002      northern ireland  2019-12-01        27434.0   \n",
       "1069  S92000003              scotland  2019-12-01        30000.0   \n",
       "1070  W92000004                 wales  2019-12-01        27500.0   \n",
       "\n",
       "      life_satisfaction mean_salary recycling_pct  population_size  \\\n",
       "0                   NaN       48922             0           6581.0   \n",
       "1                   NaN       23620             3         162444.0   \n",
       "2                   NaN       23128             8         313469.0   \n",
       "3                   NaN       21386            18         217458.0   \n",
       "4                   NaN       20911             6         260317.0   \n",
       "...                 ...         ...           ...              ...   \n",
       "1066                NaN       37603           NaN              NaN   \n",
       "1067                NaN       37865           NaN              NaN   \n",
       "1068                NaN       32083           NaN              NaN   \n",
       "1069                NaN       34916           NaN              NaN   \n",
       "1070                NaN       31251           NaN              NaN   \n",
       "\n",
       "      number_of_jobs  area_size  no_of_houses  borough_flag  \n",
       "0                NaN        NaN           NaN             1  \n",
       "1                NaN        NaN           NaN             1  \n",
       "2                NaN        NaN           NaN             1  \n",
       "3                NaN        NaN           NaN             1  \n",
       "4                NaN        NaN           NaN             1  \n",
       "...              ...        ...           ...           ...  \n",
       "1066             NaN        NaN           NaN             0  \n",
       "1067             NaN        NaN           NaN             0  \n",
       "1068             NaN        NaN           NaN             0  \n",
       "1069             NaN        NaN           NaN             0  \n",
       "1070             NaN        NaN           NaN             0  \n",
       "\n",
       "[1071 rows x 12 columns]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0       1999\n",
       "1       1999\n",
       "2       1999\n",
       "3       1999\n",
       "4       1999\n",
       "        ... \n",
       "1066    2019\n",
       "1067    2019\n",
       "1068    2019\n",
       "1069    2019\n",
       "1070    2019\n",
       "Name: date, Length: 1071, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
    "\n",
    "housing_df = pd.read_csv(url)\n",
    "\n",
    "display(housing_df.info)\n",
    "\n",
    "year_col = housing_df['date'].str.split('-').str.get(0)\n",
    "\n",
    "# Test\n",
    "display(year_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPAgjR5U1utf"
   },
   "source": [
    "### Exercise 2\n",
    "---\n",
    "\n",
    "In exercise 1 you have extracted the year, but it's dtype is 'object' (it is still a string).  You can convert to integer by adding  .astype(int) to the daisychain.\n",
    "\n",
    "**Test output**:  \n",
    "\n",
    "```\n",
    "...\n",
    "Name: year, Length: 1071, dtype: int64\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3SuKrrvD2f1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1999\n",
       "1       1999\n",
       "2       1999\n",
       "3       1999\n",
       "4       1999\n",
       "        ... \n",
       "1066    2019\n",
       "1067    2019\n",
       "1068    2019\n",
       "1069    2019\n",
       "1070    2019\n",
       "Name: date, Length: 1071, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "year_col = year_col.astype('int64')\n",
    "\n",
    "display(year_col)\n",
    "\n",
    "# Add nex column to the dataframe\n",
    "housing_df['Year'] = year_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spoUBwxT2gSi"
   },
   "source": [
    "### Exercise 3\n",
    "---\n",
    "\n",
    "All the areas in the data set are in lower case.  To prepare the data for reporting, you may want to capitalise.  Use .str.title() to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5fLUjUYk4AyI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             City Of London\n",
       "1       Barking And Dagenham\n",
       "2                     Barnet\n",
       "3                     Bexley\n",
       "4                      Brent\n",
       "                ...         \n",
       "1066           Great Britain\n",
       "1067       England And Wales\n",
       "1068        Northern Ireland\n",
       "1069                Scotland\n",
       "1070                   Wales\n",
       "Name: area, Length: 1071, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "housing_df['area'] = housing_df['area'].str.title()\n",
    "\n",
    "# Test\n",
    "display(housing_df['area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuUQQF2a4CPX"
   },
   "source": [
    "### Exercise 4 - Filter all areas to find all with 'and' in the name\n",
    "---\n",
    "\n",
    "Use str.contains() and a search (e.g. df[df['area'].str.contains()) to filter for all areas with 'and' in the name\n",
    "\n",
    "**Test output**:  \n",
    "105 rows × 13 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pmT32YMq4BA8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>area</th>\n",
       "      <th>date</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>life_satisfaction</th>\n",
       "      <th>mean_salary</th>\n",
       "      <th>recycling_pct</th>\n",
       "      <th>population_size</th>\n",
       "      <th>number_of_jobs</th>\n",
       "      <th>area_size</th>\n",
       "      <th>no_of_houses</th>\n",
       "      <th>borough_flag</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>Barking And Dagenham</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>21480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23620</td>\n",
       "      <td>3</td>\n",
       "      <td>162444.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>Hammersmith And Fulham</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28555</td>\n",
       "      <td>7</td>\n",
       "      <td>160634.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>E09000020</td>\n",
       "      <td>Kensington And Chelsea</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>20646.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28074</td>\n",
       "      <td>13</td>\n",
       "      <td>147678.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>E12000003</td>\n",
       "      <td>Yorkshire And The Humber</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>16527.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18977</td>\n",
       "      <td>7</td>\n",
       "      <td>4956325.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>K04000001</td>\n",
       "      <td>England And Wales</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>17974.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51933471.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>Barking And Dagenham</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>28738.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>Hammersmith And Fulham</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>37990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>E09000020</td>\n",
       "      <td>Kensington And Chelsea</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>33000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>E12000003</td>\n",
       "      <td>Yorkshire And The Humber</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>27835.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>K04000001</td>\n",
       "      <td>England And Wales</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>30500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           code                      area        date  median_salary  \\\n",
       "1     E09000002      Barking And Dagenham  1999-12-01        21480.0   \n",
       "12    E09000013    Hammersmith And Fulham  1999-12-01        25000.0   \n",
       "19    E09000020    Kensington And Chelsea  1999-12-01        20646.0   \n",
       "35    E12000003  Yorkshire And The Humber  1999-12-01        16527.0   \n",
       "47    K04000001         England And Wales  1999-12-01        17974.0   \n",
       "...         ...                       ...         ...            ...   \n",
       "1021  E09000002      Barking And Dagenham  2019-12-01        28738.0   \n",
       "1032  E09000013    Hammersmith And Fulham  2019-12-01        37990.0   \n",
       "1039  E09000020    Kensington And Chelsea  2019-12-01        33000.0   \n",
       "1055  E12000003  Yorkshire And The Humber  2019-12-01        27835.0   \n",
       "1067  K04000001         England And Wales  2019-12-01        30500.0   \n",
       "\n",
       "      life_satisfaction mean_salary recycling_pct  population_size  \\\n",
       "1                   NaN       23620             3         162444.0   \n",
       "12                  NaN       28555             7         160634.0   \n",
       "19                  NaN       28074            13         147678.0   \n",
       "35                  NaN       18977             7        4956325.0   \n",
       "47                  NaN       21549           NaN       51933471.0   \n",
       "...                 ...         ...           ...              ...   \n",
       "1021                NaN       32010           NaN              NaN   \n",
       "1032                NaN       48362           NaN              NaN   \n",
       "1039                NaN       41741           NaN              NaN   \n",
       "1055                NaN       32653           NaN              NaN   \n",
       "1067                NaN       37865           NaN              NaN   \n",
       "\n",
       "      number_of_jobs  area_size  no_of_houses  borough_flag  Year  \n",
       "1                NaN        NaN           NaN             1  1999  \n",
       "12               NaN        NaN           NaN             1  1999  \n",
       "19               NaN        NaN           NaN             1  1999  \n",
       "35               NaN        NaN           NaN             0  1999  \n",
       "47               NaN        NaN           NaN             0  1999  \n",
       "...              ...        ...           ...           ...   ...  \n",
       "1021             NaN        NaN           NaN             1  2019  \n",
       "1032             NaN        NaN           NaN             1  2019  \n",
       "1039             NaN        NaN           NaN             1  2019  \n",
       "1055             NaN        NaN           NaN             0  2019  \n",
       "1067             NaN        NaN           NaN             0  2019  \n",
       "\n",
       "[105 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(housing_df[housing_df['area'].str.contains('And')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ChmyffT7wDK"
   },
   "source": [
    "### Exercise 4\n",
    "---\n",
    "\n",
    "Filter the data for all areas starting with 'ba'  \n",
    "\n",
    "Test output:  \n",
    "21 rows, all city of london"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "li8sAN3O8Zxp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>area</th>\n",
       "      <th>date</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>life_satisfaction</th>\n",
       "      <th>mean_salary</th>\n",
       "      <th>recycling_pct</th>\n",
       "      <th>population_size</th>\n",
       "      <th>number_of_jobs</th>\n",
       "      <th>area_size</th>\n",
       "      <th>no_of_houses</th>\n",
       "      <th>borough_flag</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>Barking And Dagenham</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>21480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23620</td>\n",
       "      <td>3</td>\n",
       "      <td>162444.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>Barnet</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>19568.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23128</td>\n",
       "      <td>8</td>\n",
       "      <td>313469.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        code                  area        date  median_salary  \\\n",
       "1  E09000002  Barking And Dagenham  1999-12-01        21480.0   \n",
       "2  E09000003                Barnet  1999-12-01        19568.0   \n",
       "\n",
       "   life_satisfaction mean_salary recycling_pct  population_size  \\\n",
       "1                NaN       23620             3         162444.0   \n",
       "2                NaN       23128             8         313469.0   \n",
       "\n",
       "   number_of_jobs  area_size  no_of_houses  borough_flag  Year  \n",
       "1             NaN        NaN           NaN             1  1999  \n",
       "2             NaN        NaN           NaN             1  1999  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter = housing_df[housing_df['area'].str.startswith('Ba')]\n",
    "\n",
    "# Drop duplicates to only display unique areas starting with Ba \n",
    "display (filter.drop_duplicates(subset = ['area']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrSsOstK8Z9_"
   },
   "source": [
    "### Exercise 5\n",
    "---\n",
    "Filter the data for all areas ending with 'ham', for the year 2000\n",
    "\n",
    "**Test output**:  \n",
    "4 rows (barking and dagenham, hammersmith and fulham, lewisham, newham)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "lMJckNo-ab3z"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>area</th>\n",
       "      <th>date</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>life_satisfaction</th>\n",
       "      <th>mean_salary</th>\n",
       "      <th>recycling_pct</th>\n",
       "      <th>population_size</th>\n",
       "      <th>number_of_jobs</th>\n",
       "      <th>area_size</th>\n",
       "      <th>no_of_houses</th>\n",
       "      <th>borough_flag</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>Barking And Dagenham</td>\n",
       "      <td>2000-12-01</td>\n",
       "      <td>22618.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24696</td>\n",
       "      <td>4</td>\n",
       "      <td>163893.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>Hammersmith And Fulham</td>\n",
       "      <td>2000-12-01</td>\n",
       "      <td>25264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28742</td>\n",
       "      <td>8</td>\n",
       "      <td>164393.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>E09000023</td>\n",
       "      <td>Lewisham</td>\n",
       "      <td>2000-12-01</td>\n",
       "      <td>22357.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22659</td>\n",
       "      <td>5</td>\n",
       "      <td>252106.0</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>E09000025</td>\n",
       "      <td>Newham</td>\n",
       "      <td>2000-12-01</td>\n",
       "      <td>19437.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21609</td>\n",
       "      <td>3</td>\n",
       "      <td>245463.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         code                    area        date  median_salary  \\\n",
       "52  E09000002    Barking And Dagenham  2000-12-01        22618.0   \n",
       "63  E09000013  Hammersmith And Fulham  2000-12-01        25264.0   \n",
       "73  E09000023                Lewisham  2000-12-01        22357.0   \n",
       "75  E09000025                  Newham  2000-12-01        19437.0   \n",
       "\n",
       "    life_satisfaction mean_salary recycling_pct  population_size  \\\n",
       "52                NaN       24696             4         163893.0   \n",
       "63                NaN       28742             8         164393.0   \n",
       "73                NaN       22659             5         252106.0   \n",
       "75                NaN       21609             3         245463.0   \n",
       "\n",
       "    number_of_jobs  area_size  no_of_houses  borough_flag  Year  \n",
       "52         57000.0        NaN           NaN             1  2000  \n",
       "63        120000.0        NaN           NaN             1  2000  \n",
       "73         76000.0        NaN           NaN             1  2000  \n",
       "75         79000.0        NaN           NaN             1  2000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(housing_df[housing_df['area'].str.endswith('ham') & (housing_df['Year'] == 2000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_niKyF39X4q"
   },
   "source": [
    "### Exercise 6 - new data set\n",
    "---\n",
    "\n",
    "Use the data set here:  https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\n",
    "\n",
    "Read the data from the sheet 'Skill Migration'  \n",
    "\n",
    "Inspect the data, then create a new dataframe with the following changes:\n",
    "\n",
    "1.  Remove the word 'Skills' from the 'skill_group_category' column  \n",
    "2.  Convert country_code to uppercase  \n",
    "3.  Filter for regions containing 'Asia'\n",
    "4.  Remove the skill_group_id and the wb_income columns\n",
    "\n",
    "**Test output**:  \n",
    "9969 rows × 10 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "UGfVBX1FCjZj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       country_code country_name   wb_income            wb_region  \\\n",
       "0               af  Afghanistan  Low income           South Asia   \n",
       "1               af  Afghanistan  Low income           South Asia   \n",
       "2               af  Afghanistan  Low income           South Asia   \n",
       "3               af  Afghanistan  Low income           South Asia   \n",
       "4               af  Afghanistan  Low income           South Asia   \n",
       "...            ...          ...         ...                  ...   \n",
       "17612           zw     Zimbabwe  Low income  Sub-Saharan Africa    \n",
       "17613           zw     Zimbabwe  Low income  Sub-Saharan Africa    \n",
       "17614           zw     Zimbabwe  Low income  Sub-Saharan Africa    \n",
       "17615           zw     Zimbabwe  Low income  Sub-Saharan Africa    \n",
       "17616           zw     Zimbabwe  Low income  Sub-Saharan Africa    \n",
       "\n",
       "       skill_group_id         skill_group_category        skill_group_name  \\\n",
       "0                2549                  Tech Skills  Information Management   \n",
       "1                2608              Business Skills  Operational Efficiency   \n",
       "2                3806  Specialized Industry Skills       National Security   \n",
       "3               50321                  Tech Skills        Software Testing   \n",
       "4                1606  Specialized Industry Skills                    Navy   \n",
       "...               ...                          ...                     ...   \n",
       "17612           12666  Specialized Industry Skills                Teaching   \n",
       "17613            1235  Specialized Industry Skills                  Mining   \n",
       "17614           43756  Specialized Industry Skills       Personal Coaching   \n",
       "17615            1724  Specialized Industry Skills           Public Health   \n",
       "17616             172  Specialized Industry Skills                     Law   \n",
       "\n",
       "       net_per_10K_2015  net_per_10K_2016  net_per_10K_2017  ...  Unnamed: 19  \\\n",
       "0               -791.59           -705.88           -550.04  ...          NaN   \n",
       "1              -1610.25           -933.55           -776.06  ...          NaN   \n",
       "2              -1731.45           -769.68           -756.59  ...          NaN   \n",
       "3               -957.50           -828.54           -964.73  ...          NaN   \n",
       "4              -1510.71           -841.17           -842.32  ...          NaN   \n",
       "...                 ...               ...               ...  ...          ...   \n",
       "17612             71.18             30.68            -18.85  ...          NaN   \n",
       "17613              8.97           -112.85            -35.87  ...          NaN   \n",
       "17614            -53.45            -59.70            -88.01  ...          NaN   \n",
       "17615             15.25            -65.53            -57.22  ...          NaN   \n",
       "17616             40.85             47.16            -31.24  ...          NaN   \n",
       "\n",
       "       Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  Unnamed: 24  \\\n",
       "0              NaN          NaN          NaN          NaN          NaN   \n",
       "1              NaN          NaN          NaN          NaN          NaN   \n",
       "2              NaN          NaN          NaN          NaN          NaN   \n",
       "3              NaN          NaN          NaN          NaN          NaN   \n",
       "4              NaN          NaN          NaN          NaN          NaN   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "17612          NaN          NaN          NaN          NaN          NaN   \n",
       "17613          NaN          NaN          NaN          NaN          NaN   \n",
       "17614          NaN          NaN          NaN          NaN          NaN   \n",
       "17615          NaN          NaN          NaN          NaN          NaN   \n",
       "17616          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "       Unnamed: 25  Unnamed: 26  Unnamed: 27  Unnamed: 28  \n",
       "0              NaN          NaN          NaN          NaN  \n",
       "1              NaN          NaN          NaN          NaN  \n",
       "2              NaN          NaN          NaN          NaN  \n",
       "3              NaN          NaN          NaN          NaN  \n",
       "4              NaN          NaN          NaN          NaN  \n",
       "...            ...          ...          ...          ...  \n",
       "17612          NaN          NaN          NaN          NaN  \n",
       "17613          NaN          NaN          NaN          NaN  \n",
       "17614          NaN          NaN          NaN          NaN  \n",
       "17615          NaN          NaN          NaN          NaN  \n",
       "17616          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[17617 rows x 29 columns]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>wb_region</th>\n",
       "      <th>skill_group_category</th>\n",
       "      <th>skill_group_name</th>\n",
       "      <th>net_per_10K_2015</th>\n",
       "      <th>net_per_10K_2016</th>\n",
       "      <th>net_per_10K_2017</th>\n",
       "      <th>net_per_10K_2018</th>\n",
       "      <th>net_per_10K_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Information Management</td>\n",
       "      <td>-791.59</td>\n",
       "      <td>-705.88</td>\n",
       "      <td>-550.04</td>\n",
       "      <td>-680.92</td>\n",
       "      <td>-1208.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Business</td>\n",
       "      <td>Operational Efficiency</td>\n",
       "      <td>-1610.25</td>\n",
       "      <td>-933.55</td>\n",
       "      <td>-776.06</td>\n",
       "      <td>-532.22</td>\n",
       "      <td>-790.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Specialized</td>\n",
       "      <td>National Security</td>\n",
       "      <td>-1731.45</td>\n",
       "      <td>-769.68</td>\n",
       "      <td>-756.59</td>\n",
       "      <td>-600.44</td>\n",
       "      <td>-767.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Software Testing</td>\n",
       "      <td>-957.50</td>\n",
       "      <td>-828.54</td>\n",
       "      <td>-964.73</td>\n",
       "      <td>-406.50</td>\n",
       "      <td>-739.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Specialized</td>\n",
       "      <td>Navy</td>\n",
       "      <td>-1510.71</td>\n",
       "      <td>-841.17</td>\n",
       "      <td>-842.32</td>\n",
       "      <td>-581.71</td>\n",
       "      <td>-718.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17371</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Specialized</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>658.89</td>\n",
       "      <td>291.89</td>\n",
       "      <td>-271.00</td>\n",
       "      <td>219.20</td>\n",
       "      <td>166.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17372</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Specialized</td>\n",
       "      <td>Cooking</td>\n",
       "      <td>83.81</td>\n",
       "      <td>236.02</td>\n",
       "      <td>-42.85</td>\n",
       "      <td>238.90</td>\n",
       "      <td>180.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17373</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Business</td>\n",
       "      <td>Sales Leads</td>\n",
       "      <td>511.16</td>\n",
       "      <td>98.13</td>\n",
       "      <td>-355.91</td>\n",
       "      <td>133.89</td>\n",
       "      <td>181.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Disruptive</td>\n",
       "      <td>Aerospace Engineering</td>\n",
       "      <td>410.02</td>\n",
       "      <td>42.71</td>\n",
       "      <td>-222.09</td>\n",
       "      <td>138.03</td>\n",
       "      <td>256.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Business</td>\n",
       "      <td>Revenue Analysis</td>\n",
       "      <td>315.68</td>\n",
       "      <td>158.12</td>\n",
       "      <td>101.89</td>\n",
       "      <td>277.98</td>\n",
       "      <td>267.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9969 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country_code country_name            wb_region skill_group_category  \\\n",
       "0               AF  Afghanistan           South Asia                 Tech   \n",
       "1               AF  Afghanistan           South Asia             Business   \n",
       "2               AF  Afghanistan           South Asia          Specialized   \n",
       "3               AF  Afghanistan           South Asia                 Tech   \n",
       "4               AF  Afghanistan           South Asia          Specialized   \n",
       "...            ...          ...                  ...                  ...   \n",
       "17371           VN      Vietnam  East Asia & Pacific          Specialized   \n",
       "17372           VN      Vietnam  East Asia & Pacific          Specialized   \n",
       "17373           VN      Vietnam  East Asia & Pacific             Business   \n",
       "17374           VN      Vietnam  East Asia & Pacific           Disruptive   \n",
       "17375           VN      Vietnam  East Asia & Pacific             Business   \n",
       "\n",
       "             skill_group_name  net_per_10K_2015  net_per_10K_2016  \\\n",
       "0      Information Management           -791.59           -705.88   \n",
       "1      Operational Efficiency          -1610.25           -933.55   \n",
       "2           National Security          -1731.45           -769.68   \n",
       "3            Software Testing           -957.50           -828.54   \n",
       "4                        Navy          -1510.71           -841.17   \n",
       "...                       ...               ...               ...   \n",
       "17371               Air Force            658.89            291.89   \n",
       "17372                 Cooking             83.81            236.02   \n",
       "17373             Sales Leads            511.16             98.13   \n",
       "17374   Aerospace Engineering            410.02             42.71   \n",
       "17375        Revenue Analysis            315.68            158.12   \n",
       "\n",
       "       net_per_10K_2017  net_per_10K_2018  net_per_10K_2019  \n",
       "0               -550.04           -680.92          -1208.79  \n",
       "1               -776.06           -532.22           -790.09  \n",
       "2               -756.59           -600.44           -767.64  \n",
       "3               -964.73           -406.50           -739.51  \n",
       "4               -842.32           -581.71           -718.64  \n",
       "...                 ...               ...               ...  \n",
       "17371           -271.00            219.20            166.99  \n",
       "17372            -42.85            238.90            180.90  \n",
       "17373           -355.91            133.89            181.47  \n",
       "17374           -222.09            138.03            256.55  \n",
       "17375            101.89            277.98            267.58  \n",
       "\n",
       "[9969 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skill_df = pd.read_excel(\"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\", sheet_name=\"Skill Migration\")\n",
    "\n",
    "# Show info\n",
    "display(skill_df.info)\n",
    "\n",
    "# Split around empty space, get first item\n",
    "skill_df['skill_group_category'] = skill_df['skill_group_category'].str.split(' ').str.get(0)\n",
    "\n",
    "# Capitalize country code\n",
    "skill_df['country_code'] = skill_df['country_code'].str.upper()\n",
    "\n",
    "# Store filtered results in 'filtered_df'\n",
    "filtered_df = skill_df[skill_df['wb_region'].str.contains('Asia')]\n",
    "\n",
    "# Drop columns as per specs\n",
    "filtered_df = filtered_df.drop(columns=['skill_group_id','wb_income'], axis = 1)\n",
    "\n",
    "# Drop empty columns\n",
    "filtered_df = filtered_df.dropna(axis = 1, how='all')\n",
    "\n",
    "display(filtered_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVUE_rVkCj4g"
   },
   "source": [
    "### Exercise 7 - a data cleaning function\n",
    "\n",
    "Create a function called **clean_data(df)** that perform the same actions as in Exercise 6, and will *return* the cleaned data set\n",
    "\n",
    "Format:\n",
    "\n",
    "```\n",
    "def clean_data(df):\n",
    "  # code to clean the data as in exerise 6, then return the final dataframe\n",
    "\n",
    "cleaned_data = clean_data(migration_data)\n",
    "```\n",
    "**Test output:**  \n",
    "9969 rows × 10 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "kEFpr4_5EKZ6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>wb_region</th>\n",
       "      <th>skill_group_category</th>\n",
       "      <th>skill_group_name</th>\n",
       "      <th>net_per_10K_2015</th>\n",
       "      <th>net_per_10K_2016</th>\n",
       "      <th>net_per_10K_2017</th>\n",
       "      <th>net_per_10K_2018</th>\n",
       "      <th>net_per_10K_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Information Management</td>\n",
       "      <td>-791.59</td>\n",
       "      <td>-705.88</td>\n",
       "      <td>-550.04</td>\n",
       "      <td>-680.92</td>\n",
       "      <td>-1208.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Business</td>\n",
       "      <td>Operational Efficiency</td>\n",
       "      <td>-1610.25</td>\n",
       "      <td>-933.55</td>\n",
       "      <td>-776.06</td>\n",
       "      <td>-532.22</td>\n",
       "      <td>-790.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Specialized</td>\n",
       "      <td>National Security</td>\n",
       "      <td>-1731.45</td>\n",
       "      <td>-769.68</td>\n",
       "      <td>-756.59</td>\n",
       "      <td>-600.44</td>\n",
       "      <td>-767.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Software Testing</td>\n",
       "      <td>-957.50</td>\n",
       "      <td>-828.54</td>\n",
       "      <td>-964.73</td>\n",
       "      <td>-406.50</td>\n",
       "      <td>-739.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Specialized</td>\n",
       "      <td>Navy</td>\n",
       "      <td>-1510.71</td>\n",
       "      <td>-841.17</td>\n",
       "      <td>-842.32</td>\n",
       "      <td>-581.71</td>\n",
       "      <td>-718.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17371</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Specialized</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>658.89</td>\n",
       "      <td>291.89</td>\n",
       "      <td>-271.00</td>\n",
       "      <td>219.20</td>\n",
       "      <td>166.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17372</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Specialized</td>\n",
       "      <td>Cooking</td>\n",
       "      <td>83.81</td>\n",
       "      <td>236.02</td>\n",
       "      <td>-42.85</td>\n",
       "      <td>238.90</td>\n",
       "      <td>180.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17373</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Business</td>\n",
       "      <td>Sales Leads</td>\n",
       "      <td>511.16</td>\n",
       "      <td>98.13</td>\n",
       "      <td>-355.91</td>\n",
       "      <td>133.89</td>\n",
       "      <td>181.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Disruptive</td>\n",
       "      <td>Aerospace Engineering</td>\n",
       "      <td>410.02</td>\n",
       "      <td>42.71</td>\n",
       "      <td>-222.09</td>\n",
       "      <td>138.03</td>\n",
       "      <td>256.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Business</td>\n",
       "      <td>Revenue Analysis</td>\n",
       "      <td>315.68</td>\n",
       "      <td>158.12</td>\n",
       "      <td>101.89</td>\n",
       "      <td>277.98</td>\n",
       "      <td>267.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9969 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country_code country_name            wb_region skill_group_category  \\\n",
       "0               AF  Afghanistan           South Asia                 Tech   \n",
       "1               AF  Afghanistan           South Asia             Business   \n",
       "2               AF  Afghanistan           South Asia          Specialized   \n",
       "3               AF  Afghanistan           South Asia                 Tech   \n",
       "4               AF  Afghanistan           South Asia          Specialized   \n",
       "...            ...          ...                  ...                  ...   \n",
       "17371           VN      Vietnam  East Asia & Pacific          Specialized   \n",
       "17372           VN      Vietnam  East Asia & Pacific          Specialized   \n",
       "17373           VN      Vietnam  East Asia & Pacific             Business   \n",
       "17374           VN      Vietnam  East Asia & Pacific           Disruptive   \n",
       "17375           VN      Vietnam  East Asia & Pacific             Business   \n",
       "\n",
       "             skill_group_name  net_per_10K_2015  net_per_10K_2016  \\\n",
       "0      Information Management           -791.59           -705.88   \n",
       "1      Operational Efficiency          -1610.25           -933.55   \n",
       "2           National Security          -1731.45           -769.68   \n",
       "3            Software Testing           -957.50           -828.54   \n",
       "4                        Navy          -1510.71           -841.17   \n",
       "...                       ...               ...               ...   \n",
       "17371               Air Force            658.89            291.89   \n",
       "17372                 Cooking             83.81            236.02   \n",
       "17373             Sales Leads            511.16             98.13   \n",
       "17374   Aerospace Engineering            410.02             42.71   \n",
       "17375        Revenue Analysis            315.68            158.12   \n",
       "\n",
       "       net_per_10K_2017  net_per_10K_2018  net_per_10K_2019  \n",
       "0               -550.04           -680.92          -1208.79  \n",
       "1               -776.06           -532.22           -790.09  \n",
       "2               -756.59           -600.44           -767.64  \n",
       "3               -964.73           -406.50           -739.51  \n",
       "4               -842.32           -581.71           -718.64  \n",
       "...                 ...               ...               ...  \n",
       "17371           -271.00            219.20            166.99  \n",
       "17372            -42.85            238.90            180.90  \n",
       "17373           -355.91            133.89            181.47  \n",
       "17374           -222.09            138.03            256.55  \n",
       "17375            101.89            277.98            267.58  \n",
       "\n",
       "[9969 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "migration_data = pd.read_excel(\"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\", sheet_name=\"Skill Migration\")\n",
    "\n",
    "def clean_data(df):\n",
    "    # Split around empty space, get first item\n",
    "    df['skill_group_category'] = df['skill_group_category'].str.split(' ').str.get(0)\n",
    "\n",
    "    # Capitalize country code\n",
    "    df['country_code'] = df['country_code'].str.upper()\n",
    "\n",
    "    # Store filtered results in 'filtered_df'\n",
    "    df = df[df['wb_region'].str.contains('Asia')]\n",
    "\n",
    "    # Drop columns as per specs\n",
    "    df = df.drop(columns=['skill_group_id','wb_income'], axis = 1)\n",
    "\n",
    "    # Drop empty columns\n",
    "    df = df.dropna(axis = 1, how='all')\n",
    "\n",
    "    return df\n",
    "\n",
    "cleaned_data = clean_data(migration_data)\n",
    "\n",
    "# Test\n",
    "display(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_i4oQaoEKoY"
   },
   "source": [
    "### Exercise 8\n",
    "---\n",
    "\n",
    "Write a function that will rename the net_per_10K_year columns to be just the year and will replace the 'z' (as in 'specialized') with 's' to Anglicise the spelling. The function should return the cleaned data.  \n",
    "\n",
    "Hint:  for column names, you can get the name as a string, then use find() to see if 'net_per_10K_' is in the string (the result will not be -1 if it is there), then you can replace the column name\n",
    "\n",
    "**Test output**:  \n",
    "17617 rows × 12 columns, with z replace by s in Specialized  \n",
    "Column names: country_code\tcountry_name\twb_income\twb_region\tskill_group_id\tskill_group_category\tskill_group_name\t2015\t2016\t2017\t2018\t2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "AEWS56l4JKx3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>wb_income</th>\n",
       "      <th>wb_region</th>\n",
       "      <th>skill_group_id</th>\n",
       "      <th>skill_group_category</th>\n",
       "      <th>skill_group_name</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Low income</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>2549</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Information Management</td>\n",
       "      <td>-791.59</td>\n",
       "      <td>-705.88</td>\n",
       "      <td>-550.04</td>\n",
       "      <td>-680.92</td>\n",
       "      <td>-1208.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Low income</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>2608</td>\n",
       "      <td>Business</td>\n",
       "      <td>Operational Efficiency</td>\n",
       "      <td>-1610.25</td>\n",
       "      <td>-933.55</td>\n",
       "      <td>-776.06</td>\n",
       "      <td>-532.22</td>\n",
       "      <td>-790.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Low income</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>3806</td>\n",
       "      <td>Specialised</td>\n",
       "      <td>National Security</td>\n",
       "      <td>-1731.45</td>\n",
       "      <td>-769.68</td>\n",
       "      <td>-756.59</td>\n",
       "      <td>-600.44</td>\n",
       "      <td>-767.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Low income</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>50321</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Software Testing</td>\n",
       "      <td>-957.50</td>\n",
       "      <td>-828.54</td>\n",
       "      <td>-964.73</td>\n",
       "      <td>-406.50</td>\n",
       "      <td>-739.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Low income</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>1606</td>\n",
       "      <td>Specialised</td>\n",
       "      <td>Navy</td>\n",
       "      <td>-1510.71</td>\n",
       "      <td>-841.17</td>\n",
       "      <td>-842.32</td>\n",
       "      <td>-581.71</td>\n",
       "      <td>-718.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17612</th>\n",
       "      <td>ZW</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Low income</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>12666</td>\n",
       "      <td>Specialised</td>\n",
       "      <td>Teaching</td>\n",
       "      <td>71.18</td>\n",
       "      <td>30.68</td>\n",
       "      <td>-18.85</td>\n",
       "      <td>-68.89</td>\n",
       "      <td>-93.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17613</th>\n",
       "      <td>ZW</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Low income</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>1235</td>\n",
       "      <td>Specialised</td>\n",
       "      <td>Mining</td>\n",
       "      <td>8.97</td>\n",
       "      <td>-112.85</td>\n",
       "      <td>-35.87</td>\n",
       "      <td>-65.38</td>\n",
       "      <td>-93.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17614</th>\n",
       "      <td>ZW</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Low income</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>43756</td>\n",
       "      <td>Specialised</td>\n",
       "      <td>Personal Coaching</td>\n",
       "      <td>-53.45</td>\n",
       "      <td>-59.70</td>\n",
       "      <td>-88.01</td>\n",
       "      <td>-55.90</td>\n",
       "      <td>-82.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17615</th>\n",
       "      <td>ZW</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Low income</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>1724</td>\n",
       "      <td>Specialised</td>\n",
       "      <td>Public Health</td>\n",
       "      <td>15.25</td>\n",
       "      <td>-65.53</td>\n",
       "      <td>-57.22</td>\n",
       "      <td>-39.39</td>\n",
       "      <td>-32.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17616</th>\n",
       "      <td>ZW</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Low income</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>172</td>\n",
       "      <td>Specialised</td>\n",
       "      <td>Law</td>\n",
       "      <td>40.85</td>\n",
       "      <td>47.16</td>\n",
       "      <td>-31.24</td>\n",
       "      <td>-8.24</td>\n",
       "      <td>-25.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17617 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country_code country_name   wb_income            wb_region  \\\n",
       "0               AF  Afghanistan  Low income           South Asia   \n",
       "1               AF  Afghanistan  Low income           South Asia   \n",
       "2               AF  Afghanistan  Low income           South Asia   \n",
       "3               AF  Afghanistan  Low income           South Asia   \n",
       "4               AF  Afghanistan  Low income           South Asia   \n",
       "...            ...          ...         ...                  ...   \n",
       "17612           ZW     Zimbabwe  Low income  Sub-Saharan Africa    \n",
       "17613           ZW     Zimbabwe  Low income  Sub-Saharan Africa    \n",
       "17614           ZW     Zimbabwe  Low income  Sub-Saharan Africa    \n",
       "17615           ZW     Zimbabwe  Low income  Sub-Saharan Africa    \n",
       "17616           ZW     Zimbabwe  Low income  Sub-Saharan Africa    \n",
       "\n",
       "       skill_group_id skill_group_category        skill_group_name     2015  \\\n",
       "0                2549                 Tech  Information Management  -791.59   \n",
       "1                2608             Business  Operational Efficiency -1610.25   \n",
       "2                3806          Specialised       National Security -1731.45   \n",
       "3               50321                 Tech        Software Testing  -957.50   \n",
       "4                1606          Specialised                    Navy -1510.71   \n",
       "...               ...                  ...                     ...      ...   \n",
       "17612           12666          Specialised                Teaching    71.18   \n",
       "17613            1235          Specialised                  Mining     8.97   \n",
       "17614           43756          Specialised       Personal Coaching   -53.45   \n",
       "17615            1724          Specialised           Public Health    15.25   \n",
       "17616             172          Specialised                     Law    40.85   \n",
       "\n",
       "         2016    2017    2018     2019  \n",
       "0     -705.88 -550.04 -680.92 -1208.79  \n",
       "1     -933.55 -776.06 -532.22  -790.09  \n",
       "2     -769.68 -756.59 -600.44  -767.64  \n",
       "3     -828.54 -964.73 -406.50  -739.51  \n",
       "4     -841.17 -842.32 -581.71  -718.64  \n",
       "...       ...     ...     ...      ...  \n",
       "17612   30.68  -18.85  -68.89   -93.70  \n",
       "17613 -112.85  -35.87  -65.38   -93.46  \n",
       "17614  -59.70  -88.01  -55.90   -82.23  \n",
       "17615  -65.53  -57.22  -39.39   -32.14  \n",
       "17616   47.16  -31.24   -8.24   -25.52  \n",
       "\n",
       "[17617 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def renamer(df):\n",
    "    # Drop empty columns\n",
    "    df = df.dropna(axis = 1, how='all')\n",
    "    \n",
    "    # Iterate through all the columns\n",
    "    for column in df.columns:\n",
    "        \n",
    "        # Check for the net_per_10K_ fragment of string\n",
    "        if column.find('net_per_10K_') != -1:\n",
    "            \n",
    "            # If found, create a new name by splitting the string, then taking 4th element\n",
    "            columnnew = column.split('_')[3]\n",
    "            \n",
    "            # rename the column\n",
    "            df = df.rename(columns={column: columnnew})\n",
    "    \n",
    "    # For the whole dataframe, replace Specialized with Specialised\n",
    "    df = df.replace({'Specialized': 'Specialised'})\n",
    "    return df\n",
    "\n",
    "display(renamer(migration_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pqc9I5VpJLpR"
   },
   "source": [
    "### Exercise 9\n",
    "---\n",
    "\n",
    "Read the 'Country Migration' sheet.\n",
    "\n",
    "Write a function that will:  \n",
    "*  convert the country codes to upper case  \n",
    "*  drop the lat and long columns for both base and target  \n",
    "*  rename the net_per_10K_year columns to year only  \n",
    "*  filter for base_country_wb_region contains 'Africa' and target_country_wb_region contains Asia  \n",
    "\n",
    "**Test output**:  \n",
    "```\n",
    "base_country_code\tbase_country_name\tbase_country_wb_income\tbase_country_wb_region\ttarget_country_code\ttarget_country_name\ttarget_country_wb_income\ttarget_country_wb_region\t2015\t2016\t2017\t2018\t2019\n",
    "0\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAF\tAfghanistan\tLow Income\tSouth Asia\t0.19\t0.16\t0.11\t-0.05\t-0.02\n",
    "4\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAM\tArmenia\tUpper Middle Income\tEurope & Central Asia\t0.10\t0.05\t0.03\t-0.01\t0.02\n",
    "5\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAU\tAustralia\tHigh Income\tEast Asia & Pacific\t-1.06\t-3.31\t-4.01\t-4.58\t-4.09\n",
    "6\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAT\tAustria\tHigh Income\tEurope & Central Asia\t0.11\t-0.08\t-0.07\t-0.05\t-0.16\n",
    "7\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAZ\tAzerbaijan\tUpper Middle Income\tEurope & Central Asia\t0.24\t0.25\t0.10\t0.05\t0.04\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "4132\tZM\tZambia\tLower Middle Income\tSub-Saharan Africa\tGB\tUnited Kingdom\tHigh Income\tEurope & Central Asia\t43.27\t27.60\t7.88\t6.90\t3.68\n",
    "4135\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tAU\tAustralia\tHigh Income\tEast Asia & Pacific\t-1.31\t-2.33\t-2.10\t-2.08\t-1.84\n",
    "4138\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tIS\tIceland\tHigh Income\tEurope & Central Asia\t8.52\t6.22\t2.35\t1.81\t0.97\n",
    "4142\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tNO\tNorway\tHigh Income\tEurope & Central Asia\t2.88\t6.46\t2.10\t0.33\t-0.13\n",
    "4145\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tGB\tUnited Kingdom\tHigh Income\tEurope & Central Asia\t3.91\t4.66\t0.74\t-0.66\t-1.97\n",
    "478 rows × 13 columns\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "jYu6n_jF9v1Y"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_country_code</th>\n",
       "      <th>base_country_name</th>\n",
       "      <th>base_country_wb_income</th>\n",
       "      <th>base_country_wb_region</th>\n",
       "      <th>target_country_code</th>\n",
       "      <th>target_country_name</th>\n",
       "      <th>target_country_wb_income</th>\n",
       "      <th>target_country_wb_region</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>High Income</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Low Income</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>High Income</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "      <td>AM</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>Upper Middle Income</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>High Income</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "      <td>AU</td>\n",
       "      <td>Australia</td>\n",
       "      <td>High Income</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>-3.31</td>\n",
       "      <td>-4.01</td>\n",
       "      <td>-4.58</td>\n",
       "      <td>-4.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>High Income</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "      <td>AT</td>\n",
       "      <td>Austria</td>\n",
       "      <td>High Income</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>High Income</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>Upper Middle Income</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>ZM</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>Lower Middle Income</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>GB</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>High Income</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "      <td>43.27</td>\n",
       "      <td>27.60</td>\n",
       "      <td>7.88</td>\n",
       "      <td>6.90</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>ZW</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Low Income</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>AU</td>\n",
       "      <td>Australia</td>\n",
       "      <td>High Income</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>-2.10</td>\n",
       "      <td>-2.08</td>\n",
       "      <td>-1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>ZW</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Low Income</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>IS</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>High Income</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "      <td>8.52</td>\n",
       "      <td>6.22</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>ZW</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Low Income</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>NO</td>\n",
       "      <td>Norway</td>\n",
       "      <td>High Income</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "      <td>2.88</td>\n",
       "      <td>6.46</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>ZW</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Low Income</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>GB</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>High Income</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "      <td>3.91</td>\n",
       "      <td>4.66</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-1.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     base_country_code     base_country_name base_country_wb_income  \\\n",
       "0                   AE  United Arab Emirates            High Income   \n",
       "4                   AE  United Arab Emirates            High Income   \n",
       "5                   AE  United Arab Emirates            High Income   \n",
       "6                   AE  United Arab Emirates            High Income   \n",
       "7                   AE  United Arab Emirates            High Income   \n",
       "...                ...                   ...                    ...   \n",
       "4132                ZM                Zambia    Lower Middle Income   \n",
       "4135                ZW              Zimbabwe             Low Income   \n",
       "4138                ZW              Zimbabwe             Low Income   \n",
       "4142                ZW              Zimbabwe             Low Income   \n",
       "4145                ZW              Zimbabwe             Low Income   \n",
       "\n",
       "          base_country_wb_region target_country_code target_country_name  \\\n",
       "0     Middle East & North Africa                  AF         Afghanistan   \n",
       "4     Middle East & North Africa                  AM             Armenia   \n",
       "5     Middle East & North Africa                  AU           Australia   \n",
       "6     Middle East & North Africa                  AT             Austria   \n",
       "7     Middle East & North Africa                  AZ          Azerbaijan   \n",
       "...                          ...                 ...                 ...   \n",
       "4132          Sub-Saharan Africa                  GB      United Kingdom   \n",
       "4135          Sub-Saharan Africa                  AU           Australia   \n",
       "4138          Sub-Saharan Africa                  IS             Iceland   \n",
       "4142          Sub-Saharan Africa                  NO              Norway   \n",
       "4145          Sub-Saharan Africa                  GB      United Kingdom   \n",
       "\n",
       "     target_country_wb_income target_country_wb_region   2015   2016  2017  \\\n",
       "0                  Low Income               South Asia   0.19   0.16  0.11   \n",
       "4         Upper Middle Income    Europe & Central Asia   0.10   0.05  0.03   \n",
       "5                 High Income      East Asia & Pacific  -1.06  -3.31 -4.01   \n",
       "6                 High Income    Europe & Central Asia   0.11  -0.08 -0.07   \n",
       "7         Upper Middle Income    Europe & Central Asia   0.24   0.25  0.10   \n",
       "...                       ...                      ...    ...    ...   ...   \n",
       "4132              High Income    Europe & Central Asia  43.27  27.60  7.88   \n",
       "4135              High Income      East Asia & Pacific  -1.31  -2.33 -2.10   \n",
       "4138              High Income    Europe & Central Asia   8.52   6.22  2.35   \n",
       "4142              High Income    Europe & Central Asia   2.88   6.46  2.10   \n",
       "4145              High Income    Europe & Central Asia   3.91   4.66  0.74   \n",
       "\n",
       "      2018  2019  \n",
       "0    -0.05 -0.02  \n",
       "4    -0.01  0.02  \n",
       "5    -4.58 -4.09  \n",
       "6    -0.05 -0.16  \n",
       "7     0.05  0.04  \n",
       "...    ...   ...  \n",
       "4132  6.90  3.68  \n",
       "4135 -2.08 -1.84  \n",
       "4138  1.81  0.97  \n",
       "4142  0.33 -0.13  \n",
       "4145 -0.66 -1.97  \n",
       "\n",
       "[478 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "migration_country = pd.read_excel(\"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\", sheet_name=\"Country Migration\")\n",
    "\n",
    "def cleaner_2(df):\n",
    "    \n",
    "    # Capitalize country codes\n",
    "    df['base_country_code'] = df['base_country_code'].str.upper()\n",
    "    df['target_country_code'] = df['target_country_code'].str.upper()\n",
    "    \n",
    "    # Drop columns as per specs\n",
    "    df = df.drop(columns=['base_lat', 'base_long', 'target_lat', 'target_long'], axis = 1)\n",
    "    \n",
    "    # Run the previously created renamer function to change columns' names as per specs\n",
    "    df = renamer(df)\n",
    "    \n",
    "    # Filter as per specs\n",
    "    df = df[df['base_country_wb_region'].str.contains('Africa') & df['target_country_wb_region'].str.contains('Asia')]\n",
    "    \n",
    "    return df\n",
    "\n",
    "display(cleaner_2(migration_country))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7V6mNsfsNrsd"
   },
   "source": [
    "### Exercise 10\n",
    "---\n",
    "\n",
    "Read the data from file 'https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv'.\n",
    "\n",
    "Write a function that will return a new dataframe with just the married women listed, surname only.\n",
    "\n",
    "**Test output**:  \n",
    "```\n",
    "\tPassengerId\tSurvived\tPclass\tName\tSex\tAge\tSibSp\tParch\tTicket\tFare\tCabin\tEmbarked\n",
    "1\t2\t1\t1\tCumings\tfemale\t38.0\t1\t0\tPC 17599\t71.2833\tC85\tC\n",
    "3\t4\t1\t1\tFutrelle\tfemale\t35.0\t1\t0\t113803\t53.1000\tC123\tS\n",
    "8\t9\t1\t3\tJohnson\tfemale\t27.0\t0\t2\t347742\t11.1333\tNaN\tS\n",
    "9\t10\t1\t2\tNasser\tfemale\t14.0\t1\t0\t237736\t30.0708\tNaN\tC\n",
    "15\t16\t1\t2\tHewlett\tfemale\t55.0\t0\t0\t248706\t16.0000\tNaN\tS\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "871\t872\t1\t1\tBeckwith\tfemale\t47.0\t1\t1\t11751\t52.5542\tD35\tS\n",
    "874\t875\t1\t2\tAbelson\tfemale\t28.0\t1\t0\tP/PP 3381\t24.0000\tNaN\tC\n",
    "879\t880\t1\t1\tPotter\tfemale\t56.0\t0\t1\t11767\t83.1583\tC50\tC\n",
    "880\t881\t1\t2\tShelley\tfemale\t25.0\t0\t1\t230433\t26.0000\tNaN\tS\n",
    "885\t886\t0\t3\tRice\tfemale\t39.0\t0\t5\t382652\t29.1250\tNaN\tQ\n",
    "129 rows × 12 columns\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "id": "J4gx3RHIOczI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-247-131e21031a15>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Name'] = df['Name'].str.split(',').str.get(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Abelson</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>P/PP 3381</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Potter</td>\n",
       "      <td>female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C50</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Shelley</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>230433</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass      Name     Sex   Age  SibSp  Parch  \\\n",
       "1              2         1       1   Cumings  female  38.0      1      0   \n",
       "3              4         1       1  Futrelle  female  35.0      1      0   \n",
       "8              9         1       3   Johnson  female  27.0      0      2   \n",
       "9             10         1       2    Nasser  female  14.0      1      0   \n",
       "15            16         1       2   Hewlett  female  55.0      0      0   \n",
       "..           ...       ...     ...       ...     ...   ...    ...    ...   \n",
       "871          872         1       1  Beckwith  female  47.0      1      1   \n",
       "874          875         1       2   Abelson  female  28.0      1      0   \n",
       "879          880         1       1    Potter  female  56.0      0      1   \n",
       "880          881         1       2   Shelley  female  25.0      0      1   \n",
       "885          886         0       3      Rice  female  39.0      0      5   \n",
       "\n",
       "        Ticket     Fare Cabin Embarked  \n",
       "1     PC 17599  71.2833   C85        C  \n",
       "3       113803  53.1000  C123        S  \n",
       "8       347742  11.1333   NaN        S  \n",
       "9       237736  30.0708   NaN        C  \n",
       "15      248706  16.0000   NaN        S  \n",
       "..         ...      ...   ...      ...  \n",
       "871      11751  52.5542   D35        S  \n",
       "874  P/PP 3381  24.0000   NaN        C  \n",
       "879      11767  83.1583   C50        C  \n",
       "880     230433  26.0000   NaN        S  \n",
       "885     382652  29.1250   NaN        Q  \n",
       "\n",
       "[129 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic = pd.read_csv('https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv')\n",
    "\n",
    "\n",
    "def married_filter(df):\n",
    "    \n",
    "    # Filter only passengers with Mrs title\n",
    "    df = df[df['Name'].str.contains('Mrs.')]\n",
    "    \n",
    "    # Split the name around the comma, then access 1st item on the list\n",
    "    df['Name'] = df['Name'].str.split(',').str.get(0)\n",
    "    return df\n",
    "\n",
    "# Test\n",
    "display(married_filter(titanic))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Working with Strings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
